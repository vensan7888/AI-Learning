# This Repo is about sharing my learning in building various AI applications from basic to complex level.**

## Episode 2 
* end to end demo https://www.youtube.com/watch?v=G__8n5N1BDM of ``simple-agent`` & ``mistral-bot``
# simple-agent : 
Demonstrates how to quickly setup an agent with simple steps.

# mistral-bot
Demostrates how to setup an llm in personal laptops
* Build a chatbot
* Set Context
* Set Conginitive memory

## Episode 3 
* end to end demo https://youtu.be/r4GVkMY5UCY of ``Running Multi Models Locally``
# ollama : https://youtu.be/-Pvnrwggdks
This Video demonstrates the basic usage of 'Ollama' in Personal laptop locally.
* Run a LLM supported ollama

# ollama - create model: https://youtu.be/8Z7OjzHL5aM
This Video Demonstrates the usage of 'Ollama' to create a custom language model in personal laptop locally.
* A Food nutritionist bot

# build ollama bot: https://youtu.be/PhnrVbtmUvA
This Video Demonstrates building an application using LLMs by leveraging the power of 'Ollama', 
without running Ollama commands.
* Build a chatbot

# ollama - build multi LLM pipeline: https://youtu.be/wqG7MD_swyM
This Video Demonstrates, How to harness the power of 'Ollama' to build multi language model AI application pipeline in personal laptop locally.
* Build a blog writer
* Create content with `mistral` model
* Refine the content with `llama3.2` model.

# build multi model application: https://youtu.be/VyD62tX0GtM
This Video Demonstrates, How to build a multi model application using an Image to text, refining text & text to image models.
* Build a image re-imagine application
* Use Image to text model to describe image using `llava:7b`
* Refine image description using `llama3.2`
* Re-Imagine the image using the image description using `runwayml/stable-diffusion-v1-5` & `stabilityai/sd-turbo` models.

## Episode 4 
* end to end demo https://youtu.be/iTYq6l08Exo of ``Build RAG applications``
In this episode, I demonstrate how to build simple yet practical RAG (Retrieval-Augmented Generation) applications using Mistral and Llama 3.2 running locally via Ollama.
* We walk through working with both local and remote knowledge sources, store them in a vector database (FAISS), and enhance the system with persistent storage so knowledge can be reused across sessions.

## Episode 5 
* end to end demo https://youtu.be/xAkGOZPXtCY of ``Langchain & Langgraph applications``
* I walk you through practical, real-world implementations of LangChain and LangGraph to help you truly understand how modern LLM applications are designed and orchestrated.
* Instead of just theory, this session focuses on building actual applications — from RAG-based document search to persistent chatbots and graph-based content workflows.
* If you’ve been confused about when to use LangChain vs LangGraph, this episode will give you the clarity you need.

